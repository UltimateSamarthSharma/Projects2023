{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aff2e13-f59a-438c-852c-442dbed5e4a0",
   "metadata": {},
   "source": [
    "Go to this given URL and solve the following questions:<br>\n",
    "URL: https://www.youtube.com/@PW-Foundation/videos<br>\n",
    "Q1. Write a python program to extract the video URL of the first five videos.<br>\n",
    "Q2. Write a python program to extract the URL of the video thumbnails of the first five videos.<br>\n",
    "Q3. Write a python program to extract the title of the first five videos.<br>\n",
    "Q4. Write a python program to extract the number of views of the first five videos.<br>\n",
    "Q5. Write a python program to extract the time of posting of video for the first five videos.<br>\n",
    "Note: Save all the data scraped in the above questions in a CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d84ea7-4edb-4fbd-b0a9-24afc4f60162",
   "metadata": {},
   "source": [
    "**Scraping requrired data from YouTube was not possible with BeautifulSoup so I had to use another python package called Selenium.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b385030-0c46-4181-ab18-ef01170112d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "PATH = \"C:\\Program Files (x86)\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(PATH)\n",
    "def lauchpage():\n",
    "\tdriver.get(\"https://www.youtube.com/@PW-Foundation/videos\")\n",
    "\ttry:\n",
    "\t\tvid_details = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.ID, \"contents\")))\n",
    "\texcept:\n",
    "\t\tdriver.quit()\n",
    "\treturn vid_details.text\n",
    "vid_info = lauchpage()\n",
    "data_dict = {}\n",
    "line_num = 1\n",
    "all_lines=[]\n",
    "for line in vid_info.split('\\n'):\n",
    "\tif ':' in line:\n",
    "\t\tpass\n",
    "\telse:\n",
    "\t\tall_lines.append(line)\n",
    "for line in all_lines:\n",
    "    if line_num % 3 == 1:\n",
    "        record_dict = {}\n",
    "    if line_num % 3 == 1:\n",
    "        record_dict['title'] = line\n",
    "    elif line_num % 3 == 2:\n",
    "        record_dict['views'] = line\n",
    "    elif line_num % 3 == 0:\n",
    "        record_dict['posting_time'] = line\n",
    "        data_dict[len(data_dict)] = record_dict\n",
    "    line_num+=1\n",
    "df = pd.DataFrame.from_dict(data_dict, orient='index')\n",
    "df.to_csv('pwskills_youtube_vid_details.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ffb1ff-b4ac-48a9-b761-a1c98e15d49e",
   "metadata": {},
   "source": [
    "Link To The CSV File: https://github.com/UltimateSamarthSharma/Projects2023/blob/main/youtube-scraper-main/pwskills_youtube_vid_details.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c86e288-97bb-487f-b50d-fcfba16111ab",
   "metadata": {},
   "source": [
    "I forgot to scrap the video links as well and by the time i realized, i was too far in to the project and i would have to do everything from the start if i wanted to scrap the links as well.\n",
    "\n",
    "As for the video thumbnails, i was unable to scrap them but i am pretty sure if i spent more time on it i will eventually figure it out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d95caa-96c3-482f-a4af-e53a5ec742c5",
   "metadata": {},
   "source": [
    "**Code for the Flask Front-End:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bbe17f-e2cb-4042-a2c4-f1d600b7b645",
   "metadata": {},
   "source": [
    "application.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3048c8a-1825-4453-8ebd-d067320ef4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template\n",
    "from flask_cors import CORS,cross_origin\n",
    "import csv\n",
    "application = Flask(__name__)\n",
    "app=application\n",
    "csv_filename = 'pwskills_youtube_vid_details - Copy.csv'\n",
    "details=[]\n",
    "with open(csv_filename,'r') as data:\n",
    "    for line in csv.reader(data):\n",
    "        mydict = {\"Index\": line[0], \"Title\": line[1], \"Views\": line[2], \"Time_since_posted\": line[3]}\n",
    "        details.append(mydict)\n",
    "@app.route(\"/\")\n",
    "@cross_origin()\n",
    "def home():\n",
    "\treturn render_template('index.html',details=details)\n",
    "if __name__==\"__main__\":\n",
    "    app.run(host='127.0.0.1', port=8000, debug=True)\n",
    "\t#app.run(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358d224f-1fbc-4549-aa63-704f6d33d79c",
   "metadata": {},
   "source": [
    "index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33955889-937f-4124-8d55-057d9e24d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "\t<meta charset=\"utf-8\">\n",
    "\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "\t<title>Output File</title>\n",
    "</head>\n",
    "<body>\n",
    "\t<table cellspacing=\"0\">\n",
    "        <tr>\n",
    "            <th>Index</th>\n",
    "            <th>Title</th>\n",
    "            <th>Views</th>\n",
    "            <th>Time Since Posted</th>\n",
    "        </tr>\n",
    "            {% for detail in details %}\n",
    "        <tr>\n",
    "            <td>{{detail.Index}}</td>\n",
    "            <td>{{detail.Title}}</td>\n",
    "            <td>{{detail.Views}}</td>\n",
    "            <td>{{detail.Time_since_posted}}</td>\n",
    "            {% endfor %}\n",
    "        </tr>\n",
    "    </table>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cf7ead-0fda-47a1-b960-f2a01caa423d",
   "metadata": {},
   "source": [
    "**Link to the GitHub Folder of this project:**\n",
    "\n",
    "It contains all the files and everything regarding this project.<br>\n",
    "https://github.com/UltimateSamarthSharma/Projects2023/tree/main/youtube-scraper-main"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
