{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5591c7e2-0459-4abd-906d-cd621f8969cf",
   "metadata": {},
   "source": [
    "**Q1. Install and load the latest versions of TensorFlow and Keras. Print their versions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64265ac4-b1c9-4075-8d86-73a0af4ddb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow keras\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885febaa-e7bf-4d84-aaa3-7ea8c72777bc",
   "metadata": {},
   "source": [
    "**Q2. Load the Wine Quality dataset and explore its dimensions.**<br>Dataset link: **https://www.kaggle.com/datasets/nareshbhat/wine-quality-binary-classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51304ce7-48f8-4051-973d-4aeec25a4c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have downloaded the dataset and it is in the current working directory\n",
    "data = pd.read_csv('winequality.csv')\n",
    "\n",
    "# Explore the dimensions of the dataset\n",
    "print(\"Dataset dimensions:\", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa45da7-a023-469f-a4bb-dafdb4fc6489",
   "metadata": {},
   "source": [
    "**Q3. Check for null values, identify categorical variables, and encode them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbda23f-a026-47b7-b8c4-1ed7f85bb5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "print(\"Null values:\\n\", data.isnull().sum())\n",
    "\n",
    "# Identify categorical variables\n",
    "categorical_vars = ['type']\n",
    "\n",
    "# Encode categorical variables\n",
    "data_encoded = pd.get_dummies(data, columns=categorical_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cca2bc-275a-4275-ad58-60ba845b8e5e",
   "metadata": {},
   "source": [
    "**Q4. Separate the features and target variables from the dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610a9cb7-3a0f-4d33-b009-c8a24b82bc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_encoded.drop('quality', axis=1)\n",
    "target = data_encoded['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c05224-3e7b-4396-a989-d964d0cbec8e",
   "metadata": {},
   "source": [
    "**Q5. Perform a train-test split, dividing the data into training, validation, and test datasets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3008ca77-a88c-4614-8d3d-9b9d2315e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the train set into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0287c2b9-5022-48b2-a44a-f41e26055979",
   "metadata": {},
   "source": [
    "**Q6. Scale the dataset using an appropriate scaling technique.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824d84f9-fd0c-4df4-affd-b9dc11d95faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a1bb8d-9582-4922-ba21-bfe37c558ec7",
   "metadata": {},
   "source": [
    "**Q7. Design and implement at least two hidden layers and an output layer for the binary categorical variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d11313d-15a4-45da-b0d1-653a7a442b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "# Design the model architecture\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f3c01f-867a-4982-989b-0b1e143a680f",
   "metadata": {},
   "source": [
    "**Q8. Create a Sequential model in Keras and add the previously designed layers to it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cba8c3-2434-4981-b236-838988ee6712",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b089e9f3-5ff6-48f6-9e10-3ec9c2e4749e",
   "metadata": {},
   "source": [
    "**Q9. Print the summary of the model architecture.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1640615-a29c-42a8-903d-db9de21f2fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15ad84f-a16f-4b37-a258-f693de5364b8",
   "metadata": {},
   "source": [
    "**Q10. Set the loss function(‘binary_crossentropy’), optimizer, and include the accuracy metric in the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ab7468-3a80-46cc-9b0f-8bb2b65c8afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fcde8d-ac35-4a8b-b75f-b2ed47a48e89",
   "metadata": {},
   "source": [
    "**Q11. Compile the model with the specified loss function, optimizer, and metrics.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf6ed82-bbbf-4270-b432-d31959a388db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cec2787-5c4e-449c-9dc3-7f98a984dd19",
   "metadata": {},
   "source": [
    "**Q12. Fit the model to the training data using appropriate batch size and number of epochs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd3e7a6-a46b-478f-9e9f-d8d1fd652cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_scaled, y_train, batch_size=32, epochs=10, validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e67644-7764-4a2f-8597-399486afc5de",
   "metadata": {},
   "source": [
    "**Q13. Obtain the model's parameters (weights and biases).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed102b8-d29c-4cdb-acb0-c8186c42d120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model's parameters\n",
    "model_params = model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edeb334-7f09-4d53-b232-92951d5fa9fa",
   "metadata": {},
   "source": [
    "**Q14. Store the model's training history as a Pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927448fd-4573-4ed0-af7a-fa31357a7029",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1cbc4f-722e-4f66-bd19-c6ec2d40263b",
   "metadata": {},
   "source": [
    "**Q15. Plot the training history (e.g., accuracy and loss) using suitable visualization techniques.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5278e3c-e193-4a56-8fda-57241d98eafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c367bd49-6924-4890-a93e-cf3f8f7bdfea",
   "metadata": {},
   "source": [
    "**Q16. Evaluate the model's performance using the test dataset and report relevant metrics.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b4890c-de4b-40cd-9797-8e09eb29e028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
